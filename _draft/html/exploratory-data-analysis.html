<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3 Exploratory Data Analysis | Binary Classification Using Six Machine Learning Techniques</title>
  <meta name="description" content="Binary classification using six machine learning techniques (PCA, Logit, SVM-Linear, SVM-Polynomial, SVM-RBF, Neural Network) are tested for accuracy and False Positives/False Negatives using myoglobin &amp; control set. “Binary Classification Using Six Machine Learning Techniques, Tested Against Accuracy And False Positives/False Negatives Using Myoglobin Proteins Vs. Control Set”" />
  <meta name="generator" content="bookdown 0.18 and GitBook 2.6.7" />

  <meta property="og:title" content="3 Exploratory Data Analysis | Binary Classification Using Six Machine Learning Techniques" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Binary classification using six machine learning techniques (PCA, Logit, SVM-Linear, SVM-Polynomial, SVM-RBF, Neural Network) are tested for accuracy and False Positives/False Negatives using myoglobin &amp; control set. “Binary Classification Using Six Machine Learning Techniques, Tested Against Accuracy And False Positives/False Negatives Using Myoglobin Proteins Vs. Control Set”" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3 Exploratory Data Analysis | Binary Classification Using Six Machine Learning Techniques" />
  
  <meta name="twitter:description" content="Binary classification using six machine learning techniques (PCA, Logit, SVM-Linear, SVM-Polynomial, SVM-RBF, Neural Network) are tested for accuracy and False Positives/False Negatives using myoglobin &amp; control set. “Binary Classification Using Six Machine Learning Techniques, Tested Against Accuracy And False Positives/False Negatives Using Myoglobin Proteins Vs. Control Set”" />
  

<meta name="author" content="Matthew C. Curcio" />


<meta name="date" content="2020-03-18" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="introduction-what-is-machine-learning.html"/>
<link rel="next" href="principle-component-analysis-of-a-binary-classification-system.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/kePrint-0.0.1/kePrint.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preface</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#welcome"><i class="fa fa-check"></i>Welcome</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#who-this-book-is-for"><i class="fa fa-check"></i>Who This Book Is For</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgments"><i class="fa fa-check"></i>Acknowledgments</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#dedication"><i class="fa fa-check"></i>Dedication</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-the-author"><i class="fa fa-check"></i>About the Author</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introduction-what-is-machine-learning.html"><a href="introduction-what-is-machine-learning.html"><i class="fa fa-check"></i><b>2</b> Introduction - What is Machine Learning?</a><ul>
<li class="chapter" data-level="2.1" data-path="introduction-what-is-machine-learning.html"><a href="introduction-what-is-machine-learning.html#machine-learning-is"><i class="fa fa-check"></i><b>2.1</b> Machine Learning Is?</a><ul>
<li class="chapter" data-level="2.1.1" data-path="introduction-what-is-machine-learning.html"><a href="introduction-what-is-machine-learning.html#what-is-predictive-modeling"><i class="fa fa-check"></i><b>2.1.1</b> What is Predictive Modeling?</a></li>
<li class="chapter" data-level="2.1.2" data-path="introduction-what-is-machine-learning.html"><a href="introduction-what-is-machine-learning.html#supervised-learning"><i class="fa fa-check"></i><b>2.1.2</b> Supervised Learning</a></li>
<li class="chapter" data-level="2.1.3" data-path="introduction-what-is-machine-learning.html"><a href="introduction-what-is-machine-learning.html#unsupervised-learning"><i class="fa fa-check"></i><b>2.1.3</b> Unsupervised Learning</a></li>
<li class="chapter" data-level="2.1.4" data-path="introduction-what-is-machine-learning.html"><a href="introduction-what-is-machine-learning.html#five-challenges-in-predictive-modeling"><i class="fa fa-check"></i><b>2.1.4</b> Five Challenges In Predictive Modeling</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="introduction-what-is-machine-learning.html"><a href="introduction-what-is-machine-learning.html#research-description"><i class="fa fa-check"></i><b>2.2</b> Research Description</a><ul>
<li class="chapter" data-level="2.2.1" data-path="introduction-what-is-machine-learning.html"><a href="introduction-what-is-machine-learning.html#exploratory-data-analysis-eda"><i class="fa fa-check"></i><b>2.2.1</b> Exploratory Data Analysis (EDA)</a></li>
<li class="chapter" data-level="2.2.2" data-path="introduction-what-is-machine-learning.html"><a href="introduction-what-is-machine-learning.html#caret-library-for-r"><i class="fa fa-check"></i><b>2.2.2</b> Caret library for R</a></li>
<li class="chapter" data-level="2.2.3" data-path="introduction-what-is-machine-learning.html"><a href="introduction-what-is-machine-learning.html#tuning-hyper-parameters"><i class="fa fa-check"></i><b>2.2.3</b> Tuning Hyper-parameters</a></li>
<li class="chapter" data-level="2.2.4" data-path="introduction-what-is-machine-learning.html"><a href="introduction-what-is-machine-learning.html#k-fold-cross-validation-of-results"><i class="fa fa-check"></i><b>2.2.4</b> K-Fold Cross validation of results</a></li>
<li class="chapter" data-level="2.2.5" data-path="introduction-what-is-machine-learning.html"><a href="introduction-what-is-machine-learning.html#train-command"><i class="fa fa-check"></i><b>2.2.5</b> Train command</a></li>
<li class="chapter" data-level="2.2.6" data-path="introduction-what-is-machine-learning.html"><a href="introduction-what-is-machine-learning.html#analysis-of-results"><i class="fa fa-check"></i><b>2.2.6</b> Analysis of results</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html"><i class="fa fa-check"></i><b>3</b> Exploratory Data Analysis</a><ul>
<li class="chapter" data-level="3.1" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#introduction"><i class="fa fa-check"></i><b>3.1</b> Introduction</a><ul>
<li class="chapter" data-level="3.1.1" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#four-step-analysis"><i class="fa fa-check"></i><b>3.1.1</b> Four-Step Analysis</a></li>
<li class="chapter" data-level="3.1.2" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#useful-guides-for-exploratory-data-analysis"><i class="fa fa-check"></i><b>3.1.2</b> Useful Guides for Exploratory Data Analysis</a></li>
<li class="chapter" data-level="3.1.3" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#questions-during-eda"><i class="fa fa-check"></i><b>3.1.3</b> Questions During EDA</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#analysis-of-raw-data"><i class="fa fa-check"></i><b>3.2</b> Analysis of RAW data</a><ul>
<li class="chapter" data-level="3.2.1" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#visually-inspect-raw-data-files"><i class="fa fa-check"></i><b>3.2.1</b> Visually inspect RAW data files</a></li>
<li class="chapter" data-level="3.2.2" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#inspect-raw-dataframe-structure-str"><i class="fa fa-check"></i><b>3.2.2</b> Inspect RAW dataframe structure, <code>str()</code></a></li>
<li class="chapter" data-level="3.2.3" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#check-raw-data-head-tail"><i class="fa fa-check"></i><b>3.2.3</b> Check RAW data <code>head</code> &amp; <code>tail</code></a></li>
<li class="chapter" data-level="3.2.4" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#check-raw-data-types"><i class="fa fa-check"></i><b>3.2.4</b> Check RAW data types</a></li>
<li class="chapter" data-level="3.2.5" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#check-raw-dataframe-dimensions"><i class="fa fa-check"></i><b>3.2.5</b> Check RAW dataframe dimensions</a></li>
<li class="chapter" data-level="3.2.6" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#check-raw-for-missing-values"><i class="fa fa-check"></i><b>3.2.6</b> Check RAW for missing values</a></li>
<li class="chapter" data-level="3.2.7" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#number-of-polypeptides-per-class"><i class="fa fa-check"></i><b>3.2.7</b> Number of polypeptides per Class:</a></li>
<li class="chapter" data-level="3.2.8" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#numerical-summary-of-raw-data"><i class="fa fa-check"></i><b>3.2.8</b> Numerical summary of RAW data</a></li>
<li class="chapter" data-level="3.2.9" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#visualize-descriptive-statistics-using-raw-data"><i class="fa fa-check"></i><b>3.2.9</b> Visualize Descriptive Statistics using RAW Data</a></li>
<li class="chapter" data-level="3.2.10" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#scatter-plot-of-means-of-myoglobin-control-amino-acid-composition-of-raw-data"><i class="fa fa-check"></i><b>3.2.10</b> Scatter plot of means of <em>Myoglobin-Control</em> amino acid composition of RAW Data</a></li>
<li class="chapter" data-level="3.2.11" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#means-of-percent-amino-acid-composition-of-control-myoglobin-categories-raw-data"><i class="fa fa-check"></i><b>3.2.11</b> Means of percent amino acid composition of control &amp; myoglobin categories, RAW data</a></li>
<li class="chapter" data-level="3.2.12" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#boxplots-of-grand-means-of-overall-amino-acid-composition-raw-data"><i class="fa fa-check"></i><b>3.2.12</b> Boxplots of grand-means of overall amino acid composition, RAW data</a></li>
<li class="chapter" data-level="3.2.13" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#boxplots-of-amino-acid-compositions-for-control-only-raw-data"><i class="fa fa-check"></i><b>3.2.13</b> Boxplots of amino acid compositions for control (only), RAW data</a></li>
<li class="chapter" data-level="3.2.14" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#boxplots-of-amino-acid-compositions-for-myoglobin-only-raw-data"><i class="fa fa-check"></i><b>3.2.14</b> Boxplots of amino acid compositions for myoglobin (only), RAW data</a></li>
<li class="chapter" data-level="3.2.15" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#boxplots-of-length-of-polypeptides-for-raw-data"><i class="fa fa-check"></i><b>3.2.15</b> Boxplots Of Length Of Polypeptides For RAW Data</a></li>
<li class="chapter" data-level="3.2.16" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#plot-coefficient-of-variance-for-raw-data"><i class="fa fa-check"></i><b>3.2.16</b> Plot Coefficient Of Variance For RAW Data</a></li>
<li class="chapter" data-level="3.2.17" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#skewness-of-distributions-raw-data"><i class="fa fa-check"></i><b>3.2.17</b> Skewness of distributions, RAW data</a></li>
<li class="chapter" data-level="3.2.18" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#determine-coefficients-of-correlation-raw-data"><i class="fa fa-check"></i><b>3.2.18</b> Determine coefficients of correlation, RAW data</a></li>
<li class="chapter" data-level="3.2.19" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#boruta-random-forest-test-raw-data"><i class="fa fa-check"></i><b>3.2.19</b> Boruta Random Forest Test, RAW data</a></li>
<li class="chapter" data-level="3.2.20" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#plot-variable-importance-raw-data"><i class="fa fa-check"></i><b>3.2.20</b> Plot variable importance, RAW Data</a></li>
<li class="chapter" data-level="3.2.21" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#variable-importance-scores-raw-data"><i class="fa fa-check"></i><b>3.2.21</b> Variable importance scores, RAW Data</a></li>
<li class="chapter" data-level="3.2.22" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#conclusion-for-boruta-random-forest-test-raw-data"><i class="fa fa-check"></i><b>3.2.22</b> Conclusion for Boruta random forest test, RAW Data</a></li>
<li class="chapter" data-level="3.2.23" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#conclusions-for-eda-raw-data"><i class="fa fa-check"></i><b>3.2.23</b> Conclusions For EDA, RAW data</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#analysis-of-transformed-data"><i class="fa fa-check"></i><b>3.3</b> Analysis of TRANSFORMED data</a><ul>
<li class="chapter" data-level="3.3.1" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#check-transformed-dataframe-dimensions"><i class="fa fa-check"></i><b>3.3.1</b> Check Transformed dataframe dimensions</a></li>
<li class="chapter" data-level="3.3.2" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#check-transformed-for-missing-values"><i class="fa fa-check"></i><b>3.3.2</b> Check Transformed for missing values</a></li>
<li class="chapter" data-level="3.3.3" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#count-transformed-data-for-the-number-of-polypeptides-per-class"><i class="fa fa-check"></i><b>3.3.3</b> Count Transformed data for the number of polypeptides per class</a></li>
<li class="chapter" data-level="3.3.4" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#visualization-descriptive-statistics-transformed-data"><i class="fa fa-check"></i><b>3.3.4</b> Visualization Descriptive Statistics, TRANSFORMED data</a></li>
<li class="chapter" data-level="3.3.5" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#scatter-plot-of-means-of-myoglobin-control-amino-acid-composition-sqrt-x_i-transformed-data"><i class="fa fa-check"></i><b>3.3.5</b> Scatter plot of means of <em>Myoglobin-Control</em> amino acid composition <span class="math inline">\(\sqrt x_i\)</span>, TRANSFORMED data</a></li>
<li class="chapter" data-level="3.3.6" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#grouped-bar-chart-of-means-for-percent-amino-acid-composition-of-transformed-data-control-myoglobin-categories"><i class="fa fa-check"></i><b>3.3.6</b> Grouped bar chart of means for percent amino acid composition of Transformed Data; control &amp; myoglobin categories</a></li>
<li class="chapter" data-level="3.3.7" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#boxplots-of-grand-means-of-the-overall-amino-acid-composition-of-square-root-transformed-data"><i class="fa fa-check"></i><b>3.3.7</b> Boxplots of grand-means of the overall amino acid composition of square-root transformed data</a></li>
<li class="chapter" data-level="3.3.8" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#boxplots-of-amino-acid-compositions-for-control-only-of-square-root-transformed-data"><i class="fa fa-check"></i><b>3.3.8</b> Boxplots of amino acid compositions for control (only) of square-root transformed data</a></li>
<li class="chapter" data-level="3.3.9" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#boxplots-of-amino-acid-compositions-for-myoglobin-of-square-root-transformed-dataonly-transformed-data"><i class="fa fa-check"></i><b>3.3.9</b> Boxplots of amino acid compositions for myoglobin of square-root transformed Data(only), TRANSFORMED data</a></li>
<li class="chapter" data-level="3.3.10" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#boxplots-of-length-of-polypeptides-of-transformed-data-myoglobin-control-combined"><i class="fa fa-check"></i><b>3.3.10</b> Boxplots Of Length Of Polypeptides Of Transformed Data; Myoglobin, Control &amp; Combined</a></li>
<li class="chapter" data-level="3.3.11" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#coefficient-of-variance-cv-transformed-data"><i class="fa fa-check"></i><b>3.3.11</b> Coefficient of Variance (CV), TRANSFORMED data</a></li>
<li class="chapter" data-level="3.3.12" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#plot-of-coefficient-of-variance-cv"><i class="fa fa-check"></i><b>3.3.12</b> Plot of Coefficient Of Variance (CV)</a></li>
<li class="chapter" data-level="3.3.13" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#skewness-of-distributions-transformed-data"><i class="fa fa-check"></i><b>3.3.13</b> Skewness of distributions, TRANSFORMED data</a></li>
<li class="chapter" data-level="3.3.14" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#determine-coefficients-of-correlation-transformed-data"><i class="fa fa-check"></i><b>3.3.14</b> Determine coefficients of correlation, TRANSFORMED data</a></li>
<li class="chapter" data-level="3.3.15" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#boruta---dimensionality-reduction-transformed-data"><i class="fa fa-check"></i><b>3.3.15</b> Boruta - Dimensionality Reduction, TRANSFORMED data</a></li>
<li class="chapter" data-level="3.3.16" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#plot-variable-importance-transformed-data"><i class="fa fa-check"></i><b>3.3.16</b> Plot Variable Importance, TRANSFORMED data</a></li>
<li class="chapter" data-level="3.3.17" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#variable-importance-scores-transformed-data"><i class="fa fa-check"></i><b>3.3.17</b> Variable Importance Scores, TRANSFORMED data</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#eda-conclusion"><i class="fa fa-check"></i><b>3.4</b> EDA Conclusion</a><ul>
<li class="chapter" data-level="3.4.1" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#feature-selection-extraction"><i class="fa fa-check"></i><b>3.4.1</b> Feature Selection &amp; Extraction</a></li>
<li class="chapter" data-level="3.4.2" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#information-block"><i class="fa fa-check"></i><b>3.4.2</b> Information Block**</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="principle-component-analysis-of-a-binary-classification-system.html"><a href="principle-component-analysis-of-a-binary-classification-system.html"><i class="fa fa-check"></i><b>4</b> Principle Component Analysis of A Binary Classification System</a><ul>
<li class="chapter" data-level="4.1" data-path="principle-component-analysis-of-a-binary-classification-system.html"><a href="principle-component-analysis-of-a-binary-classification-system.html#introduction-1"><i class="fa fa-check"></i><b>4.1</b> Introduction</a><ul>
<li class="chapter" data-level="4.1.1" data-path="principle-component-analysis-of-a-binary-classification-system.html"><a href="principle-component-analysis-of-a-binary-classification-system.html#advantages-of-using-pca-include"><i class="fa fa-check"></i><b>4.1.1</b> Advantages Of Using PCA Include</a></li>
<li class="chapter" data-level="4.1.2" data-path="principle-component-analysis-of-a-binary-classification-system.html"><a href="principle-component-analysis-of-a-binary-classification-system.html#disadvantages-of-pca-should-be-considered"><i class="fa fa-check"></i><b>4.1.2</b> Disadvantages Of PCA Should Be Considered</a></li>
<li class="chapter" data-level="4.1.3" data-path="principle-component-analysis-of-a-binary-classification-system.html"><a href="principle-component-analysis-of-a-binary-classification-system.html#data-centering-scaling-normalization"><i class="fa fa-check"></i><b>4.1.3</b> Data centering / scaling / normalization</a></li>
<li class="chapter" data-level="4.1.4" data-path="principle-component-analysis-of-a-binary-classification-system.html"><a href="principle-component-analysis-of-a-binary-classification-system.html#histograms-of-scaled-vs.-unscaled-data"><i class="fa fa-check"></i><b>4.1.4</b> Histograms of Scaled Vs. Unscaled data</a></li>
<li class="chapter" data-level="4.1.5" data-path="principle-component-analysis-of-a-binary-classification-system.html"><a href="principle-component-analysis-of-a-binary-classification-system.html#finding-the-covariance-matrix"><i class="fa fa-check"></i><b>4.1.5</b> Finding the Covariance Matrix</a></li>
<li class="chapter" data-level="" data-path="principle-component-analysis-of-a-binary-classification-system.html"><a href="principle-component-analysis-of-a-binary-classification-system.html#covariance-of-two-variables"><i class="fa fa-check"></i>Covariance of two variables</a></li>
<li class="chapter" data-level="" data-path="principle-component-analysis-of-a-binary-classification-system.html"><a href="principle-component-analysis-of-a-binary-classification-system.html#covariance-of-matrices"><i class="fa fa-check"></i>Covariance of matrices</a></li>
<li class="chapter" data-level="4.1.6" data-path="principle-component-analysis-of-a-binary-classification-system.html"><a href="principle-component-analysis-of-a-binary-classification-system.html#finding-pca-via-singular-value-decomposition"><i class="fa fa-check"></i><b>4.1.6</b> Finding PCA via singular value decomposition</a></li>
<li class="chapter" data-level="4.1.7" data-path="principle-component-analysis-of-a-binary-classification-system.html"><a href="principle-component-analysis-of-a-binary-classification-system.html#example-of-two-dimensional-pca-using-random-data"><i class="fa fa-check"></i><b>4.1.7</b> Example of two-dimensional PCA using random data</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="principle-component-analysis-of-a-binary-classification-system.html"><a href="principle-component-analysis-of-a-binary-classification-system.html#principle-component-analysis-using-norm_c_m_20aa"><i class="fa fa-check"></i><b>4.2</b> Principle component analysis using <code>norm_c_m_20aa</code></a><ul>
<li class="chapter" data-level="4.2.1" data-path="principle-component-analysis-of-a-binary-classification-system.html"><a href="principle-component-analysis-of-a-binary-classification-system.html#screeplot-cumulative-proportion-of-variance-plot"><i class="fa fa-check"></i><b>4.2.1</b> Screeplot &amp; Cumulative Proportion of Variance plot</a></li>
<li class="chapter" data-level="4.2.2" data-path="principle-component-analysis-of-a-binary-classification-system.html"><a href="principle-component-analysis-of-a-binary-classification-system.html#biplots"><i class="fa fa-check"></i><b>4.2.2</b> Biplots</a></li>
<li class="chapter" data-level="4.2.3" data-path="principle-component-analysis-of-a-binary-classification-system.html"><a href="principle-component-analysis-of-a-binary-classification-system.html#obtain-anomalous-points-from-biplot-2-pc1-vs.-pc2"><i class="fa fa-check"></i><b>4.2.3</b> Obtain Anomalous Points From Biplot #2: PC1 Vs. PC2</a></li>
<li class="chapter" data-level="4.2.4" data-path="principle-component-analysis-of-a-binary-classification-system.html"><a href="principle-component-analysis-of-a-binary-classification-system.html#outliers-from-principal-component-1"><i class="fa fa-check"></i><b>4.2.4</b> Outliers from Principal Component-1</a></li>
<li class="chapter" data-level="4.2.5" data-path="principle-component-analysis-of-a-binary-classification-system.html"><a href="principle-component-analysis-of-a-binary-classification-system.html#outliers-from-principal-component-2"><i class="fa fa-check"></i><b>4.2.5</b> Outliers from Principal Component-2</a></li>
<li class="chapter" data-level="4.2.6" data-path="principle-component-analysis-of-a-binary-classification-system.html"><a href="principle-component-analysis-of-a-binary-classification-system.html#list-of-all-outliers-union-and-sorted-found-using-the-ruleset-1-through-4"><i class="fa fa-check"></i><b>4.2.6</b> List of all outliers (union and sorted) found using the ruleset 1 through 4</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="principle-component-analysis-of-a-binary-classification-system.html"><a href="principle-component-analysis-of-a-binary-classification-system.html#pca-conclusion"><i class="fa fa-check"></i><b>4.3</b> PCA Conclusion</a><ul>
<li class="chapter" data-level="4.3.1" data-path="principle-component-analysis-of-a-binary-classification-system.html"><a href="principle-component-analysis-of-a-binary-classification-system.html#outliers-derived-from-pc1-vs-pc2"><i class="fa fa-check"></i><b>4.3.1</b> Outliers derived from PC1 Vs PC2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="logistic-regression-for-binary-classification.html"><a href="logistic-regression-for-binary-classification.html"><i class="fa fa-check"></i><b>5</b> Logistic Regression For Binary Classification</a><ul>
<li class="chapter" data-level="5.1" data-path="logistic-regression-for-binary-classification.html"><a href="logistic-regression-for-binary-classification.html#introduction-2"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="logistic-regression-for-binary-classification.html"><a href="logistic-regression-for-binary-classification.html#logit-20-training-using-20-features"><i class="fa fa-check"></i><b>5.2</b> Logit-20 Training Using 20 Features</a><ul>
<li class="chapter" data-level="5.2.1" data-path="logistic-regression-for-binary-classification.html"><a href="logistic-regression-for-binary-classification.html#logit-20-summary-1"><i class="fa fa-check"></i><b>5.2.1</b> Logit-20 Summary #1</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="logistic-regression-for-binary-classification.html"><a href="logistic-regression-for-binary-classification.html#logit-9-training-using-9-features"><i class="fa fa-check"></i><b>5.3</b> Logit-9 Training Using 9 Features</a><ul>
<li class="chapter" data-level="5.3.1" data-path="logistic-regression-for-binary-classification.html"><a href="logistic-regression-for-binary-classification.html#logit-9-summary"><i class="fa fa-check"></i><b>5.3.1</b> Logit-9 Summary</a></li>
<li class="chapter" data-level="5.3.2" data-path="logistic-regression-for-binary-classification.html"><a href="logistic-regression-for-binary-classification.html#logit-9-confusion-matrix"><i class="fa fa-check"></i><b>5.3.2</b> Logit-9 Confusion Matrix</a></li>
<li class="chapter" data-level="5.3.3" data-path="logistic-regression-for-binary-classification.html"><a href="logistic-regression-for-binary-classification.html#obtain-list-of-false-positives-false-negatives-from-logit-9"><i class="fa fa-check"></i><b>5.3.3</b> Obtain List of False Positives &amp; False Negatives From Logit-9</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="logistic-regression-for-binary-classification.html"><a href="logistic-regression-for-binary-classification.html#logit-conclusion"><i class="fa fa-check"></i><b>5.4</b> Logit Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="neural-networks-for-binary-classification.html"><a href="neural-networks-for-binary-classification.html"><i class="fa fa-check"></i><b>6</b> Neural Networks For Binary Classification</a><ul>
<li class="chapter" data-level="6.1" data-path="neural-networks-for-binary-classification.html"><a href="neural-networks-for-binary-classification.html#introduction-3"><i class="fa fa-check"></i><b>6.1</b> Introduction</a><ul>
<li class="chapter" data-level="6.1.1" data-path="neural-networks-for-binary-classification.html"><a href="neural-networks-for-binary-classification.html#the-one-neuron-system"><i class="fa fa-check"></i><b>6.1.1</b> The One Neuron System</a></li>
<li class="chapter" data-level="6.1.2" data-path="neural-networks-for-binary-classification.html"><a href="neural-networks-for-binary-classification.html#the-two-neuron-system"><i class="fa fa-check"></i><b>6.1.2</b> The Two Neuron System</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="neural-networks-for-binary-classification.html"><a href="neural-networks-for-binary-classification.html#neural-network-experiment-for-binary-classification"><i class="fa fa-check"></i><b>6.2</b> Neural Network Experiment For Binary Classification</a><ul>
<li class="chapter" data-level="6.2.1" data-path="neural-networks-for-binary-classification.html"><a href="neural-networks-for-binary-classification.html#train-model-with-neural-networks"><i class="fa fa-check"></i><b>6.2.1</b> Train model with neural networks</a></li>
<li class="chapter" data-level="6.2.2" data-path="neural-networks-for-binary-classification.html"><a href="neural-networks-for-binary-classification.html#confusion-matrix-and-statistics"><i class="fa fa-check"></i><b>6.2.2</b> Confusion Matrix and Statistics</a></li>
<li class="chapter" data-level="6.2.3" data-path="neural-networks-for-binary-classification.html"><a href="neural-networks-for-binary-classification.html#obtain-list-of-false-positives-false-negatives"><i class="fa fa-check"></i><b>6.2.3</b> Obtain List of False Positives &amp; False Negatives</a></li>
<li class="chapter" data-level="6.2.4" data-path="neural-networks-for-binary-classification.html"><a href="neural-networks-for-binary-classification.html#false-positive-false-negative-neural-network-set"><i class="fa fa-check"></i><b>6.2.4</b> False Positive &amp; False Negative Neural Network set</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="neural-networks-for-binary-classification.html"><a href="neural-networks-for-binary-classification.html#neural-network-conclusion"><i class="fa fa-check"></i><b>6.3</b> Neural Network Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html"><i class="fa fa-check"></i><b>7</b> Support Vector Machines for Binary Classification</a><ul>
<li class="chapter" data-level="7.1" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#introduction-4"><i class="fa fa-check"></i><b>7.1</b> Introduction</a><ul>
<li class="chapter" data-level="7.1.1" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#linearly-separable"><i class="fa fa-check"></i><b>7.1.1</b> Linearly Separable</a></li>
<li class="chapter" data-level="7.1.2" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#understanding-the-hyperplane-equation"><i class="fa fa-check"></i><b>7.1.2</b> Understanding the hyperplane equation</a></li>
<li class="chapter" data-level="7.1.3" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#soft-margins"><i class="fa fa-check"></i><b>7.1.3</b> Soft Margins</a></li>
<li class="chapter" data-level="7.1.4" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#kernel-use"><i class="fa fa-check"></i><b>7.1.4</b> Kernel Use</a></li>
<li class="chapter" data-level="7.1.5" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#svm-linear-intuition"><i class="fa fa-check"></i><b>7.1.5</b> SVM-Linear Intuition</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#svm-linear-model"><i class="fa fa-check"></i><b>7.2</b> SVM-Linear Model</a><ul>
<li class="chapter" data-level="7.2.1" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#svm-linear-training"><i class="fa fa-check"></i><b>7.2.1</b> SVM-Linear Training</a></li>
<li class="chapter" data-level="7.2.2" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#svm-linear-model-summary"><i class="fa fa-check"></i><b>7.2.2</b> SVM-Linear Model Summary</a></li>
<li class="chapter" data-level="7.2.3" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#svm-linear-predict-test_set"><i class="fa fa-check"></i><b>7.2.3</b> SVM-Linear Predict test_set</a></li>
<li class="chapter" data-level="7.2.4" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#svm-linear-confusion-matrix"><i class="fa fa-check"></i><b>7.2.4</b> SVM-Linear Confusion Matrix</a></li>
<li class="chapter" data-level="7.2.5" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#svm-linear-obtain-false-positives-false-negatives"><i class="fa fa-check"></i><b>7.2.5</b> SVM-Linear Obtain False Positives &amp; False Negatives</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#svm-polynomial-model"><i class="fa fa-check"></i><b>7.3</b> SVM-Polynomial Model</a><ul>
<li class="chapter" data-level="7.3.1" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#svm-poly-training"><i class="fa fa-check"></i><b>7.3.1</b> SVM-Poly Training</a></li>
<li class="chapter" data-level="7.3.2" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#svm-poly-model-summary"><i class="fa fa-check"></i><b>7.3.2</b> SVM-Poly Model Summary</a></li>
<li class="chapter" data-level="7.3.3" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#svm-poly-predict-test_set"><i class="fa fa-check"></i><b>7.3.3</b> SVM-Poly Predict test_set</a></li>
<li class="chapter" data-level="7.3.4" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#svm-poly-confusion-matrix"><i class="fa fa-check"></i><b>7.3.4</b> SVM-Poly Confusion Matrix</a></li>
<li class="chapter" data-level="7.3.5" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#svm-poly-obtain-false-positives-false-negatives"><i class="fa fa-check"></i><b>7.3.5</b> SVM-Poly Obtain False Positives &amp; False Negatives</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#svm-rbf-model"><i class="fa fa-check"></i><b>7.4</b> SVM-RBF Model</a><ul>
<li class="chapter" data-level="7.4.1" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#svm-rbf-training"><i class="fa fa-check"></i><b>7.4.1</b> SVM-RBF Training</a></li>
<li class="chapter" data-level="7.4.2" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#svm-rbf-model-summary"><i class="fa fa-check"></i><b>7.4.2</b> SVM-RBF Model Summary</a></li>
<li class="chapter" data-level="7.4.3" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#svm-rbf-predict-test_set"><i class="fa fa-check"></i><b>7.4.3</b> SVM-RBF Predict test_set</a></li>
<li class="chapter" data-level="7.4.4" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#svm-rbf-confusion-matrix"><i class="fa fa-check"></i><b>7.4.4</b> SVM-RBF Confusion Matrix</a></li>
<li class="chapter" data-level="7.4.5" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#svm-rbf-obtain-false-positives-false-negatives"><i class="fa fa-check"></i><b>7.4.5</b> SVM-RBF Obtain False Positives &amp; False Negatives</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="support-vector-machines-for-binary-classification.html"><a href="support-vector-machines-for-binary-classification.html#svm-conclusion"><i class="fa fa-check"></i><b>7.5</b> SVM Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="results.html"><a href="results.html"><i class="fa fa-check"></i><b>8</b> Results</a><ul>
<li class="chapter" data-level="8.1" data-path="results.html"><a href="results.html#the-six-m.l-algorithms-consist-of"><i class="fa fa-check"></i><b>8.1</b> The Six M.L Algorithms consist of:</a><ul>
<li class="chapter" data-level="8.1.1" data-path="results.html"><a href="results.html#pca-anomalies-plot"><i class="fa fa-check"></i><b>8.1.1</b> PCA-Anomalies Plot</a></li>
<li class="chapter" data-level="8.1.2" data-path="results.html"><a href="results.html#logit-plot"><i class="fa fa-check"></i><b>8.1.2</b> Logit Plot</a></li>
<li class="chapter" data-level="8.1.3" data-path="results.html"><a href="results.html#svm-linear-plot"><i class="fa fa-check"></i><b>8.1.3</b> SVM-Linear Plot</a></li>
<li class="chapter" data-level="8.1.4" data-path="results.html"><a href="results.html#svm-polynomial-plot"><i class="fa fa-check"></i><b>8.1.4</b> SVM-Polynomial Plot</a></li>
<li class="chapter" data-level="8.1.5" data-path="results.html"><a href="results.html#svm-radial-basis-function-plot"><i class="fa fa-check"></i><b>8.1.5</b> SVM-Radial Basis Function Plot</a></li>
<li class="chapter" data-level="8.1.6" data-path="results.html"><a href="results.html#neural-network-function-plot"><i class="fa fa-check"></i><b>8.1.6</b> Neural Network Function Plot</a></li>
<li class="chapter" data-level="8.1.7" data-path="results.html"><a href="results.html#statistical-learning-method-vs-total-number-of-fpfn"><i class="fa fa-check"></i><b>8.1.7</b> Statistical Learning Method Vs Total Number of FP/FN</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="results.html"><a href="results.html#comparison-of-machine-learning-accuracies"><i class="fa fa-check"></i><b>8.2</b> Comparison of Machine Learning Accuracies</a><ul>
<li class="chapter" data-level="8.2.1" data-path="results.html"><a href="results.html#stacking-algorithms---run-multiple-algorithms-in-one-call."><i class="fa fa-check"></i><b>8.2.1</b> Stacking Algorithms - Run multiple algorithms in one call.</a></li>
<li class="chapter" data-level="8.2.2" data-path="results.html"><a href="results.html#plot-the-resamples-output-to-compare-the-models."><i class="fa fa-check"></i><b>8.2.2</b> Plot the resamples output to compare the models.</a></li>
<li class="chapter" data-level="8.2.3" data-path="results.html"><a href="results.html#mean-accuracies-of-m.l.-techniques-n10"><i class="fa fa-check"></i><b>8.2.3</b> Mean Accuracies of M.L. Techniques, n=10</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="conclusion.html"><a href="conclusion.html"><i class="fa fa-check"></i><b>9</b> Conclusion</a><ul>
<li class="chapter" data-level="9.1" data-path="conclusion.html"><a href="conclusion.html#comparison-of-pca-anomalies"><i class="fa fa-check"></i><b>9.1</b> Comparison of PCA Anomalies</a></li>
<li class="chapter" data-level="9.2" data-path="conclusion.html"><a href="conclusion.html#comparison-of-accuracy-measurements"><i class="fa fa-check"></i><b>9.2</b> Comparison of Accuracy Measurements</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Binary Classification Using Six Machine Learning Techniques</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="exploratory-data-analysis" class="section level1">
<h1><span class="header-section-number">3</span> Exploratory Data Analysis</h1>
<blockquote>
<p>“Exploratory data analysis (EDA) is an approach to analyzing data sets to summarize their main characteristics, often with visual methods.” <a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a></p>
</blockquote>
<div id="introduction" class="section level2">
<h2><span class="header-section-number">3.1</span> Introduction</h2>
<p>The experiment described herein involves taking groups of proteins from the Uniprot.org database and comparing how well different machine learning techniques do at separating the positive from the negative control grouping. In this circumstance, proteins from the myoglobin family are analyzed against randomly chosen human proteins, which are not related to hemoglobin or myoglobin.</p>
<p>This work is to characterize the <em>anomalous points</em> derived from PCA and compare them to the false-positives and false-negatives generated from each of six machine learning approaches produces. For the sake of this paper <em>anomalous points</em> are defined as values greater than the absolute value of three times the standard deviation from of the first and second principal components.</p>
<p><span class="math display">\[\begin{equation}
Anomalous ~Points &gt; | 3 \sigma | ~~~where~~~ \sigma = \sqrt{ \frac{1}{n-1} \sum^n_{i=1} (x_i - \bar x)^2}
\end{equation}\]</span></p>
<p>Therefore the M.L techniques will be:</p>
<ol style="list-style-type: decimal">
<li>Principal Component Analysis,</li>
<li>Logistic Regression,</li>
<li>SVM-Linear,</li>
<li>SVM-polynomial,</li>
<li>SVM-RBF,</li>
<li>Neural Network.</li>
</ol>
<div id="four-step-analysis" class="section level3">
<h3><span class="header-section-number">3.1.1</span> Four-Step Analysis</h3>
<p>At this stage, data is inspected in a careful and structured way. Hence, I have chosen a four-step process:</p>
<ol style="list-style-type: decimal">
<li>Hypothesize,</li>
<li>Summarize,</li>
<li>Visualize,</li>
<li>Normalize.</li>
</ol>
</div>
<div id="useful-guides-for-exploratory-data-analysis" class="section level3">
<h3><span class="header-section-number">3.1.2</span> Useful Guides for Exploratory Data Analysis</h3>
<p>The summarization of the amino acid dataset is based on a hybrid set of guidelines;</p>
<ol style="list-style-type: decimal">
<li>NIST Handbook of Statistics,<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a></li>
<li>Exploratory Data Analysis With R by Roger Peng,<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a></li>
<li>Exploratory Data Analysis Using R by Ronald K. Pearson.<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a></li>
</ol>
</div>
<div id="questions-during-eda" class="section level3">
<h3><span class="header-section-number">3.1.3</span> Questions During EDA</h3>
<p>Although exploratory data analysis does not always have a formal hypothesis testing portion, I do, however, pose several questions concerning the structure, quality, and types of data.</p>
<ol style="list-style-type: decimal">
<li><p>Do the independent variables of this study have large skewed distributions?</p>
<p>1.1 If skews are greater than 2.0, then can a transformation be used for normalization?</p>
<p>1.2 Determine what transformation to use?</p></li>
<li><p>Can Feature Selection be used, and which procedures are appropriate?</p>
<p>2.1 Use the Random Forest technique known as Boruta<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a> for feature importance or reduction?</p>
<p>2.2 Will coefficients of correlation (R) find collinearity and reduce the number of features?</p>
<p>2.3 Will principal component analysis (PCA) be useful in finding hidden structures of patterns?</p>
<p>2.4 Can PCA be used successfully for Feature Selection?</p></li>
<li><p>What is the structure of the data?</p>
<p>3.1 Is the data representative of the entire experimental space?</p>
<p>3.2 Is missing data an issue?</p>
<p>3.3 Does the data have certain biases, either known or unknown?</p>
<p>3.4 What relationships do we expect from these variables?<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a></p></li>
</ol>
</div>
</div>
<div id="analysis-of-raw-data" class="section level2">
<h2><span class="header-section-number">3.2</span> Analysis of RAW data</h2>
<p>Raw data is considered: <code>./00-data/02-aac_dpc_values/c_m_RAW_AAC.csv</code></p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="co"># Import libraries, NO &quot;doMC&quot;, </span></a>
<a class="sourceLine" id="cb1-2" data-line-number="2"><span class="kw">library</span>(easypackages)</a>
<a class="sourceLine" id="cb1-3" data-line-number="3"><span class="kw">libraries</span>(<span class="st">&quot;knitr&quot;</span>, <span class="st">&quot;readr&quot;</span>, <span class="st">&quot;RColorBrewer&quot;</span>, <span class="st">&quot;corrplot&quot;</span>, <span class="st">&quot;Boruta&quot;</span>, <span class="st">&quot;kableExtra&quot;</span>)</a></code></pre></div>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" data-line-number="1"><span class="co"># Import RAW data</span></a>
<a class="sourceLine" id="cb2-2" data-line-number="2">c_m_RAW_AAC &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;./00-data/02-aac_dpc_values/c_m_RAW_AAC.csv&quot;</span>)</a>
<a class="sourceLine" id="cb2-3" data-line-number="3">Class &lt;-<span class="st"> </span><span class="kw">as.factor</span>(c_m_RAW_AAC<span class="op">$</span>Class)</a></code></pre></div>
<div id="visually-inspect-raw-data-files" class="section level3">
<h3><span class="header-section-number">3.2.1</span> Visually inspect RAW data files</h3>
<ol style="list-style-type: decimal">
<li>Use the command-line interface followed by the command <code>less.</code></li>
<li>Check for binary instead of ASCII and bad Unicode.</li>
</ol>
</div>
<div id="inspect-raw-dataframe-structure-str" class="section level3">
<h3><span class="header-section-number">3.2.2</span> Inspect RAW dataframe structure, <code>str()</code></h3>
<pre><code>## Classes &#39;spec_tbl_df&#39;, &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 2340 obs. of  23 variables:
##  $ Class  : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ TotalAA: num  226 221 624 1014 699 ...
##  $ PID    : chr  &quot;C1&quot; &quot;C2&quot; &quot;C3&quot; &quot;C4&quot; ...
##  $ A      : num  0.2655 0.2081 0.0433 0.0661 0.0644 ...
##  $ C      : num  0 0 0.00962 0.01381 0.03577 ...
##  $ D      : num  0.00442 0.00452 0.04647 0.06114 0.02861 ...
##  $ E      : num  0.031 0.0271 0.0833 0.074 0.0472 ...
##  $ F      : num  0.00442 0.00452 0.02564 0.02959 0.06295 ...
##  $ G      : num  0.0708 0.0769 0.0817 0.07 0.0443 ...
##  $ H      : num  0 0 0.0176 0.0187 0.0157 ...
##  $ I      : num  0.00885 0.0181 0.03045 0.04734 0.0701 ...
##  $ K      : num  0.28761 0.27602 0.00962 0.12426 0.05579 ...
##  $ L      : num  0.0442 0.0452 0.0577 0.0888 0.1359 ...
##  $ M      : num  0.00442 0.00452 0.01442 0.02465 0.02289 ...
##  $ N      : num  0.0177 0.0136 0.0641 0.0355 0.0558 ...
##  $ P      : num  0.0841 0.0995 0.0449 0.0434 0.0472 ...
##  $ Q      : num  0.00442 0.00905 0.04327 0.03353 0.02861 ...
##  $ R      : num  0.0133 0.0181 0.1202 0.0325 0.0415 ...
##  $ S      : num  0.0575 0.0724 0.1875 0.0838 0.0787 ...
##  $ T      : num  0.0531 0.0633 0.0625 0.0414 0.0744 ...
##  $ V      : num  0.0442 0.0543 0.0385 0.0671 0.0458 ...
##  $ W      : num  0 0 0.00481 0.01282 0.00715 ...
##  $ Y      : num  0.00442 0.00452 0.01442 0.03156 0.0372 ...
##  - attr(*, &quot;spec&quot;)=
##   .. cols(
##   ..   Class = col_double(),
##   ..   TotalAA = col_double(),
##   ..   PID = col_character(),
##   ..   A = col_double(),
##   ..   C = col_double(),
##   ..   D = col_double(),
##   ..   E = col_double(),
##   ..   F = col_double(),
##   ..   G = col_double(),
##   ..   H = col_double(),
##   ..   I = col_double(),
##   ..   K = col_double(),
##   ..   L = col_double(),
##   ..   M = col_double(),
##   ..   N = col_double(),
##   ..   P = col_double(),
##   ..   Q = col_double(),
##   ..   R = col_double(),
##   ..   S = col_double(),
##   ..   T = col_double(),
##   ..   V = col_double(),
##   ..   W = col_double(),
##   ..   Y = col_double()
##   .. )</code></pre>
</div>
<div id="check-raw-data-head-tail" class="section level3">
<h3><span class="header-section-number">3.2.3</span> Check RAW data <code>head</code> &amp; <code>tail</code></h3>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" data-line-number="1"><span class="kw">head</span>(c_m_RAW_AAC, <span class="dt">n =</span> <span class="dv">2</span>)</a></code></pre></div>
<pre><code>## # A tibble: 2 x 23
##   Class TotalAA PID       A     C       D      E       F      G     H       I     K      L
##   &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;
## 1     0     226 C1    0.265     0 0.00442 0.0310 0.00442 0.0708     0 0.00885 0.288 0.0442
## 2     0     221 C2    0.208     0 0.00452 0.0271 0.00452 0.0769     0 0.0181  0.276 0.0452
## # … with 10 more variables: M &lt;dbl&gt;, N &lt;dbl&gt;, P &lt;dbl&gt;, Q &lt;dbl&gt;, R &lt;dbl&gt;, S &lt;dbl&gt;, T &lt;dbl&gt;,
## #   V &lt;dbl&gt;, W &lt;dbl&gt;, Y &lt;dbl&gt;</code></pre>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb6-1" data-line-number="1"><span class="kw">tail</span>(c_m_RAW_AAC, <span class="dt">n =</span> <span class="dv">2</span>)</a></code></pre></div>
<pre><code>## # A tibble: 2 x 23
##   Class TotalAA PID        A       C      D      E      F      G      H      I      K      L
##   &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
## 1     1     335 M1123 0.0567 0.00299 0.0537 0.0716 0.0507 0.0507 0.0388 0.0776 0.0716 0.0687
## 2     1      43 M1124 0.0698 0       0.116  0.116  0.0930 0.0465 0      0.0233 0.0233 0.0698
## # … with 10 more variables: M &lt;dbl&gt;, N &lt;dbl&gt;, P &lt;dbl&gt;, Q &lt;dbl&gt;, R &lt;dbl&gt;, S &lt;dbl&gt;, T &lt;dbl&gt;,
## #   V &lt;dbl&gt;, W &lt;dbl&gt;, Y &lt;dbl&gt;</code></pre>
</div>
<div id="check-raw-data-types" class="section level3">
<h3><span class="header-section-number">3.2.4</span> Check RAW data types</h3>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb8-1" data-line-number="1"><span class="kw">is.data.frame</span>(c_m_RAW_AAC)</a></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb10-1" data-line-number="1"><span class="kw">class</span>(c_m_RAW_AAC<span class="op">$</span>Class) <span class="co"># Col 1</span></a></code></pre></div>
<pre><code>## [1] &quot;numeric&quot;</code></pre>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb12-1" data-line-number="1"><span class="kw">class</span>(c_m_RAW_AAC<span class="op">$</span>TotalAA) <span class="co"># Col 2</span></a></code></pre></div>
<pre><code>## [1] &quot;numeric&quot;</code></pre>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb14-1" data-line-number="1"><span class="kw">class</span>(c_m_RAW_AAC<span class="op">$</span>PID) <span class="co"># Col 3</span></a></code></pre></div>
<pre><code>## [1] &quot;character&quot;</code></pre>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb16-1" data-line-number="1"><span class="kw">class</span>(c_m_RAW_AAC<span class="op">$</span>A) <span class="co"># Col 4</span></a></code></pre></div>
<pre><code>## [1] &quot;numeric&quot;</code></pre>
</div>
<div id="check-raw-dataframe-dimensions" class="section level3">
<h3><span class="header-section-number">3.2.5</span> Check RAW dataframe dimensions</h3>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb18-1" data-line-number="1"><span class="kw">dim</span>(c_m_RAW_AAC)</a></code></pre></div>
<pre><code>## [1] 2340   23</code></pre>
</div>
<div id="check-raw-for-missing-values" class="section level3">
<h3><span class="header-section-number">3.2.6</span> Check RAW for missing values</h3>
<ul>
<li><strong>No missing values found.</strong></li>
</ul>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb20-1" data-line-number="1"><span class="kw">apply</span>(<span class="kw">is.na</span>(c_m_RAW_AAC), <span class="dv">2</span>, which)</a></code></pre></div>
<pre><code>## integer(0)</code></pre>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb22-1" data-line-number="1"><span class="co"># sapply(c_m_RAW_AAC, function(x) sum(is.na(x))) # Sum up NA by columns</span></a>
<a class="sourceLine" id="cb22-2" data-line-number="2"><span class="co"># c_m_RAW_AAC[rowSums(is.na(c_m_RAW_AAC)) != 0,] # Show rows where NA&#39;s is not zero</span></a></code></pre></div>
</div>
<div id="number-of-polypeptides-per-class" class="section level3">
<h3><span class="header-section-number">3.2.7</span> Number of polypeptides per Class:</h3>
<ul>
<li>Class 0 = Control,</li>
<li>Class 1 = Myoglobin</li>
</ul>
<pre><code>## 
##    0    1 
## 1216 1124</code></pre>
</div>
<div id="numerical-summary-of-raw-data" class="section level3">
<h3><span class="header-section-number">3.2.8</span> Numerical summary of RAW data</h3>
<pre><code>##      Class           TotalAA           PID                  A                 C           
##  Min.   :0.0000   Min.   :   2.0   Length:2340        Min.   :0.00000   Min.   :0.000000  
##  1st Qu.:0.0000   1st Qu.: 109.8   Class :character   1st Qu.:0.05108   1st Qu.:0.000000  
##  Median :0.0000   Median : 154.0   Mode  :character   Median :0.07364   Median :0.007034  
##  Mean   :0.4803   Mean   : 353.8                      Mean   :0.07835   Mean   :0.011970  
##  3rd Qu.:1.0000   3rd Qu.: 407.0                      3rd Qu.:0.10261   3rd Qu.:0.020408  
##  Max.   :1.0000   Max.   :4660.0                      Max.   :0.28000   Max.   :0.159420  
##        D                 E                 F                 G                 H          
##  Min.   :0.00000   Min.   :0.00000   Min.   :0.00000   Min.   :0.00000   Min.   :0.00000  
##  1st Qu.:0.03401   1st Qu.:0.05435   1st Qu.:0.03801   1st Qu.:0.04544   1st Qu.:0.01324  
##  Median :0.05195   Median :0.07143   Median :0.04545   Median :0.06394   Median :0.02297  
##  Mean   :0.04900   Mean   :0.07451   Mean   :0.05135   Mean   :0.06193   Mean   :0.02890  
##  3rd Qu.:0.06567   3rd Qu.:0.09091   3rd Qu.:0.05501   3rd Qu.:0.08625   3rd Qu.:0.04095  
##  Max.   :0.17647   Max.   :0.50000   Max.   :0.37500   Max.   :0.36364   Max.   :0.13333  
##        I                 K                 L                 M                 N          
##  Min.   :0.00000   Min.   :0.00000   Min.   :0.00000   Min.   :0.00000   Min.   :0.00000  
##  1st Qu.:0.04348   1st Qu.:0.05797   1st Qu.:0.07480   1st Qu.:0.01087   1st Qu.:0.01948  
##  Median :0.05992   Median :0.08182   Median :0.09136   Median :0.01948   Median :0.04145  
##  Mean   :0.06839   Mean   :0.08386   Mean   :0.09313   Mean   :0.01949   Mean   :0.04228  
##  3rd Qu.:0.08216   3rd Qu.:0.12081   3rd Qu.:0.11688   3rd Qu.:0.02721   3rd Qu.:0.05788  
##  Max.   :0.50000   Max.   :0.28761   Max.   :0.25000   Max.   :0.11111   Max.   :0.12563  
##        P                 Q                 R                 S                 T          
##  Min.   :0.00000   Min.   :0.00000   Min.   :0.00000   Min.   :0.00000   Min.   :0.00000  
##  1st Qu.:0.02464   1st Qu.:0.02212   1st Qu.:0.01476   1st Qu.:0.04348   1st Qu.:0.03247  
##  Median :0.03401   Median :0.03598   Median :0.03896   Median :0.05564   Median :0.05194  
##  Mean   :0.03825   Mean   :0.03342   Mean   :0.03818   Mean   :0.06191   Mean   :0.04838  
##  3rd Qu.:0.04772   3rd Qu.:0.04545   3rd Qu.:0.05370   3rd Qu.:0.06964   3rd Qu.:0.06522  
##  Max.   :0.20635   Max.   :0.18182   Max.   :0.24324   Max.   :0.22619   Max.   :0.18750  
##        V                 W                  Y          
##  Min.   :0.00000   Min.   :0.000000   Min.   :0.00000  
##  1st Qu.:0.04575   1st Qu.:0.001899   1st Qu.:0.01463  
##  Median :0.05844   Median :0.011492   Median :0.02865  
##  Mean   :0.06512   Mean   :0.012327   Mean   :0.03644  
##  3rd Qu.:0.07405   3rd Qu.:0.017889   3rd Qu.:0.04564  
##  Max.   :0.20000   Max.   :0.133333   Max.   :0.14286</code></pre>
</div>
<div id="visualize-descriptive-statistics-using-raw-data" class="section level3">
<h3><span class="header-section-number">3.2.9</span> Visualize Descriptive Statistics using RAW Data</h3>
<p>Formulas for mean:
<span class="math display">\[\begin{equation} 
E[X] = \sum_{i=1}^n x_i p_i ~~; ~~~~~~ \bar x = \frac {1}{n} \sum_{i=1}^n x_i
\end{equation}\]</span></p>
</div>
<div id="scatter-plot-of-means-of-myoglobin-control-amino-acid-composition-of-raw-data" class="section level3">
<h3><span class="header-section-number">3.2.10</span> Scatter plot of means of <em>Myoglobin-Control</em> amino acid composition of RAW Data</h3>
<ul>
<li>This Scatter-plot shows the means for each feature (column-means) in the dataset. The means represent the ungrouped or total of all proteins (where n = 2340) versus AA type.</li>
</ul>
<p><img src="_main_files/figure-html/212-1.png" width="60%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb25-1" data-line-number="1"><span class="co"># A-4</span></a>
<a class="sourceLine" id="cb25-2" data-line-number="2"><span class="co">### Grouped barchart of amino acid vs. protein category</span></a>
<a class="sourceLine" id="cb25-3" data-line-number="3"><span class="kw">barplot</span>(percent_aa,</a>
<a class="sourceLine" id="cb25-4" data-line-number="4">        <span class="dt">main =</span> <span class="st">&quot;Mean % A.A.Composition Of 3 Protein Groupings&quot;</span>,</a>
<a class="sourceLine" id="cb25-5" data-line-number="5">        <span class="dt">ylab =</span> <span class="st">&quot;% AA Composition&quot;</span>,</a>
<a class="sourceLine" id="cb25-6" data-line-number="6">        <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">12</span>),</a>
<a class="sourceLine" id="cb25-7" data-line-number="7">        <span class="dt">col =</span> <span class="kw">colorRampPalette</span>(<span class="kw">brewer.pal</span>(<span class="dv">4</span>, <span class="st">&quot;Blues&quot;</span>))(<span class="dv">3</span>),</a>
<a class="sourceLine" id="cb25-8" data-line-number="8">        <span class="dt">legend =</span> T,</a>
<a class="sourceLine" id="cb25-9" data-line-number="9">        <span class="dt">beside =</span> T)</a></code></pre></div>
</div>
<div id="means-of-percent-amino-acid-composition-of-control-myoglobin-categories-raw-data" class="section level3">
<h3><span class="header-section-number">3.2.11</span> Means of percent amino acid composition of control &amp; myoglobin categories, RAW data</h3>
<p><img src="_main_files/figure-html/215-1.png" width="672" /></p>
</div>
<div id="boxplots-of-grand-means-of-overall-amino-acid-composition-raw-data" class="section level3">
<h3><span class="header-section-number">3.2.12</span> Boxplots of grand-means of overall amino acid composition, RAW data</h3>
<p><img src="_main_files/figure-html/216-1.png" width="672" /></p>
</div>
<div id="boxplots-of-amino-acid-compositions-for-control-only-raw-data" class="section level3">
<h3><span class="header-section-number">3.2.13</span> Boxplots of amino acid compositions for control (only), RAW data</h3>
<p><img src="_main_files/figure-html/217-1.png" width="672" /></p>
</div>
<div id="boxplots-of-amino-acid-compositions-for-myoglobin-only-raw-data" class="section level3">
<h3><span class="header-section-number">3.2.14</span> Boxplots of amino acid compositions for myoglobin (only), RAW data</h3>
<p><img src="_main_files/figure-html/218-1.png" width="672" /></p>
<p><img src="_main_files/figure-html/219-1.png" width="672" /></p>
</div>
<div id="boxplots-of-length-of-polypeptides-for-raw-data" class="section level3">
<h3><span class="header-section-number">3.2.15</span> Boxplots Of Length Of Polypeptides For RAW Data</h3>
<p><img src="_main_files/figure-html/220-1.png" width="672" /></p>
</div>
<div id="plot-coefficient-of-variance-for-raw-data" class="section level3">
<h3><span class="header-section-number">3.2.16</span> Plot Coefficient Of Variance For RAW Data</h3>
<p>Standard deviations are sensitive to scale. Therefore I compare the normalized standard deviations. This normalized standard deviation is more commonly called the coefficient of variation (CV).</p>
<p><span class="math display">\[\begin{equation} 
CV = \frac {\sigma (x)} {E [|x|]} ~~~ where ~~~ \sigma(x) \equiv \sqrt{ E[x - \mu]^2 }
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation} 
CV ~~=~~ \frac{1}{\bar x} \cdot \sqrt{ \frac{1}{n-1} \sum^n_{i=1} (x_i - \bar x)^2}
\end{equation}\]</span></p>
<p><img src="_main_files/figure-html/221-1.png" width="672" /></p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb26-1" data-line-number="1">AA_var_norm</a></code></pre></div>
<pre><code>##         A         C         D         E         F         G         H         I         K 
## 0.6095112 1.2444944 0.5478540 0.4156102 0.5436243 0.5201625 0.7966296 0.6005962 0.4689544 
##         L         M         N         P         Q         R         S         T         V 
## 0.3215591 0.6529752 0.7352478 0.7383244 0.5752622 0.7680977 0.4948690 0.5830352 0.4420595 
##         W         Y 
## 0.9461276 0.8461615</code></pre>
</div>
<div id="skewness-of-distributions-raw-data" class="section level3">
<h3><span class="header-section-number">3.2.17</span> Skewness of distributions, RAW data</h3>
<p><span class="math display">\[\begin{equation} 
Skewness ~= E\left[ \left( \frac{X - \mu}{\sigma(x)} \right)^3 \right] ~~~~ where ~~~~ \sigma(x) \equiv \sqrt{ E[x - \mu]^2 }
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation} 
Skewness ~= \frac { \frac{1}{n} \sum^n_{i=1} (x_i - \bar x)^3 } { \left( \sqrt{ \frac{1}{n-1} \sum^n_{i=1} (x_i - \bar x)^2 } \right) ^ {3}}
\end{equation}\]</span></p>
<p>Skewness values for each A.A. are determined in totality.</p>
<p><img src="_main_files/figure-html/223-1.png" width="672" /></p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb28-1" data-line-number="1">AA_skewness</a></code></pre></div>
<pre><code>##            A            C            D            E            F            G            H 
##  0.670502595  2.538162400 -0.058540442  1.782876260  2.128117638  0.091338300  1.135783661 
##            I            K            L            M            N            P            Q 
##  2.192145038  0.223433207 -0.172566877  0.744002991  0.633532783  1.493903282  0.306716333 
##            R            S            T            V            W            Y 
##  1.241930812  1.448521897 -0.006075043  1.338971930  1.831047440  1.694362388</code></pre>
</div>
<div id="determine-coefficients-of-correlation-raw-data" class="section level3">
<h3><span class="header-section-number">3.2.18</span> Determine coefficients of correlation, RAW data</h3>
<p>An easily interpretable test is a correlation 2D-plot for investigating multicollinearity or feature reduction. Fewer attributes “means decreased computational time and complexity. Secondly, if two predictors are highly correlated, this implies that they measure the same underlying information. Removing one should not compromise the performance of the model and might lead to a more parsimonious and interpretable model. Third, some models can be crippled by predictors with degenerate distributions.” <a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a></p>
<p>Pearson’s correlation coefficient:
<span class="math display">\[\begin{equation} 
\rho_{x,y} = \frac {E \left[(X - \mu_x)(X - \mu_y) \right]} {\sigma_x \sigma_y}
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation} 
r_{xy} = \frac {\sum^n_{i=1} (x_i - \bar x)(y_1 - \bar y)} { {\sqrt {\sum^n_{i=1} (x_i - \bar x)^2 }} {\sqrt {\sum^n_{i=1} (y_i - \bar y)^2 }} }
\end{equation}\]</span></p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb30-1" data-line-number="1">c_m_corr_mat &lt;-<span class="st"> </span><span class="kw">cor</span>(c_m_RAW_AAC[, <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">4</span><span class="op">:</span><span class="dv">23</span>)], <span class="dt">method =</span> <span class="st">&quot;p&quot;</span>) <span class="co"># &quot;p&quot;: Pearson test for continous variables</span></a>
<a class="sourceLine" id="cb30-2" data-line-number="2"></a>
<a class="sourceLine" id="cb30-3" data-line-number="3"><span class="kw">corrplot</span>(<span class="kw">abs</span>(c_m_corr_mat),</a>
<a class="sourceLine" id="cb30-4" data-line-number="4">         <span class="dt">title =</span> <span class="st">&quot;Correlation Plot Of AAC, RAW Data&quot;</span>,</a>
<a class="sourceLine" id="cb30-5" data-line-number="5">         <span class="dt">method =</span> <span class="st">&quot;square&quot;</span>,</a>
<a class="sourceLine" id="cb30-6" data-line-number="6">         <span class="dt">type =</span> <span class="st">&quot;lower&quot;</span>,</a>
<a class="sourceLine" id="cb30-7" data-line-number="7">         <span class="dt">tl.pos =</span> <span class="st">&quot;d&quot;</span>,</a>
<a class="sourceLine" id="cb30-8" data-line-number="8">         <span class="dt">cl.lim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>),</a>
<a class="sourceLine" id="cb30-9" data-line-number="9">         <span class="dt">addgrid.col =</span> <span class="st">&quot;lightgrey&quot;</span>,</a>
<a class="sourceLine" id="cb30-10" data-line-number="10">         <span class="dt">cl.pos =</span> <span class="st">&quot;b&quot;</span>,                   <span class="co"># Color legend position bottom.</span></a>
<a class="sourceLine" id="cb30-11" data-line-number="11">         <span class="dt">order =</span> <span class="st">&quot;FPC&quot;</span>,                  <span class="co"># &quot;FPC&quot; = first principal component order.</span></a>
<a class="sourceLine" id="cb30-12" data-line-number="12">         <span class="dt">mar =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">2</span>),</a>
<a class="sourceLine" id="cb30-13" data-line-number="13">         <span class="dt">tl.col =</span> <span class="st">&quot;black&quot;</span>)</a></code></pre></div>
<p><img src="_main_files/figure-html/225-1.png" width="672" /></p>
<p>NOTE: Amino acids shown in First Principal Component order, top to bottom.</p>
<ol style="list-style-type: decimal">
<li>Maximum value of Correlation between T &amp; N.</li>
</ol>
<pre><code>## [1] 0.7098085</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>According to Max Kuhn<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a>, correlation coefficients need only be addressed if the |R| &gt;= 0.75.</li>
<li>Therefore is <strong>no reason to consider multicollinearity</strong>.</li>
</ol>
</div>
<div id="boruta-random-forest-test-raw-data" class="section level3">
<h3><span class="header-section-number">3.2.19</span> Boruta Random Forest Test, RAW data</h3>
<blockquote>
<p>It finds relevant features by comparing original attributes’ importance with importance achievable at random, estimated using their permuted copies (shadows).</p>
<p>Miron Kursa <a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a></p>
</blockquote>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb32-1" data-line-number="1">c_m_class_<span class="dv">20</span> &lt;-<span class="st"> </span>c_m_RAW_AAC[, <span class="op">-</span><span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">3</span>)] <span class="co"># Remove TotalAA &amp; PID</span></a>
<a class="sourceLine" id="cb32-2" data-line-number="2">Class &lt;-<span class="st"> </span><span class="kw">as.factor</span>(c_m_class_<span class="dv">20</span><span class="op">$</span>Class) <span class="co"># Convert &#39;Class&#39; To Factor</span></a></code></pre></div>
<p>NOTE: <em>mcAdj = TRUE</em>, If True, multiple comparisons will be adjusted using the Bonferroni method to calculate p-values. Therefore, <span class="math inline">\(p_i \leq \large \frac {\alpha} {m}\)</span> where <span class="math inline">\(\alpha\)</span> is the desired p-value and <span class="math inline">\(m\)</span> is the total number of null hypotheses.</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb33-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">1000</span>)</a>
<a class="sourceLine" id="cb33-2" data-line-number="2"><span class="co">#registerDoMC(cores = 3) # Start multi-processor mode</span></a>
<a class="sourceLine" id="cb33-3" data-line-number="3">start_time &lt;-<span class="st"> </span><span class="kw">Sys.time</span>() <span class="co"># Start timer</span></a>
<a class="sourceLine" id="cb33-4" data-line-number="4"></a>
<a class="sourceLine" id="cb33-5" data-line-number="5">boruta_output &lt;-<span class="st"> </span><span class="kw">Boruta</span>(Class <span class="op">~</span><span class="st"> </span>.,</a>
<a class="sourceLine" id="cb33-6" data-line-number="6">                        <span class="dt">data =</span> c_m_class_<span class="dv">20</span>[, <span class="dv">-1</span>],</a>
<a class="sourceLine" id="cb33-7" data-line-number="7">                        <span class="dt">mcAdj =</span> <span class="ot">TRUE</span>, <span class="co"># See Note above.</span></a>
<a class="sourceLine" id="cb33-8" data-line-number="8">                        <span class="dt">doTrace =</span> <span class="dv">1</span>) <span class="co"># doTrace = 1, represents non-verbose mode.</span></a>
<a class="sourceLine" id="cb33-9" data-line-number="9"></a>
<a class="sourceLine" id="cb33-10" data-line-number="10"><span class="co">#registerDoSEQ() # Stop multi-processor mode</span></a>
<a class="sourceLine" id="cb33-11" data-line-number="11">end_time &lt;-<span class="st"> </span><span class="kw">Sys.time</span>() <span class="co"># End timer</span></a>
<a class="sourceLine" id="cb33-12" data-line-number="12">end_time <span class="op">-</span><span class="st"> </span>start_time <span class="co"># Display elapsed time</span></a></code></pre></div>
<pre><code>## Time difference of 29.70991 secs</code></pre>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb35-1" data-line-number="1"><span class="kw">names</span>(boruta_output)</a></code></pre></div>
</div>
<div id="plot-variable-importance-raw-data" class="section level3">
<h3><span class="header-section-number">3.2.20</span> Plot variable importance, RAW Data</h3>
<p><img src="_main_files/figure-html/230-1.png" width="672" /></p>
</div>
<div id="variable-importance-scores-raw-data" class="section level3">
<h3><span class="header-section-number">3.2.21</span> Variable importance scores, RAW Data</h3>
<table class="table table-striped table-hover" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
meanImp
</th>
<th style="text-align:left;">
decision
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
R
</td>
<td style="text-align:right;">
43.18824
</td>
<td style="text-align:left;">
Confirmed
</td>
</tr>
<tr>
<td style="text-align:left;">
H
</td>
<td style="text-align:right;">
34.29757
</td>
<td style="text-align:left;">
Confirmed
</td>
</tr>
<tr>
<td style="text-align:left;">
P
</td>
<td style="text-align:right;">
28.70225
</td>
<td style="text-align:left;">
Confirmed
</td>
</tr>
<tr>
<td style="text-align:left;">
C
</td>
<td style="text-align:right;">
27.67710
</td>
<td style="text-align:left;">
Confirmed
</td>
</tr>
<tr>
<td style="text-align:left;">
K
</td>
<td style="text-align:right;">
27.60808
</td>
<td style="text-align:left;">
Confirmed
</td>
</tr>
<tr>
<td style="text-align:left;">
E
</td>
<td style="text-align:right;">
26.18884
</td>
<td style="text-align:left;">
Confirmed
</td>
</tr>
<tr>
<td style="text-align:left;">
Y
</td>
<td style="text-align:right;">
22.85337
</td>
<td style="text-align:left;">
Confirmed
</td>
</tr>
<tr>
<td style="text-align:left;">
T
</td>
<td style="text-align:right;">
21.67689
</td>
<td style="text-align:left;">
Confirmed
</td>
</tr>
<tr>
<td style="text-align:left;">
S
</td>
<td style="text-align:right;">
21.43716
</td>
<td style="text-align:left;">
Confirmed
</td>
</tr>
<tr>
<td style="text-align:left;">
A
</td>
<td style="text-align:right;">
20.53089
</td>
<td style="text-align:left;">
Confirmed
</td>
</tr>
<tr>
<td style="text-align:left;">
N
</td>
<td style="text-align:right;">
20.09681
</td>
<td style="text-align:left;">
Confirmed
</td>
</tr>
<tr>
<td style="text-align:left;">
V
</td>
<td style="text-align:right;">
18.77054
</td>
<td style="text-align:left;">
Confirmed
</td>
</tr>
<tr>
<td style="text-align:left;">
I
</td>
<td style="text-align:right;">
18.76492
</td>
<td style="text-align:left;">
Confirmed
</td>
</tr>
<tr>
<td style="text-align:left;">
F
</td>
<td style="text-align:right;">
18.31240
</td>
<td style="text-align:left;">
Confirmed
</td>
</tr>
<tr>
<td style="text-align:left;">
D
</td>
<td style="text-align:right;">
17.64592
</td>
<td style="text-align:left;">
Confirmed
</td>
</tr>
<tr>
<td style="text-align:left;">
G
</td>
<td style="text-align:right;">
16.15461
</td>
<td style="text-align:left;">
Confirmed
</td>
</tr>
<tr>
<td style="text-align:left;">
W
</td>
<td style="text-align:right;">
15.74107
</td>
<td style="text-align:left;">
Confirmed
</td>
</tr>
<tr>
<td style="text-align:left;">
L
</td>
<td style="text-align:right;">
15.27767
</td>
<td style="text-align:left;">
Confirmed
</td>
</tr>
<tr>
<td style="text-align:left;">
M
</td>
<td style="text-align:right;">
14.82861
</td>
<td style="text-align:left;">
Confirmed
</td>
</tr>
<tr>
<td style="text-align:left;">
Q
</td>
<td style="text-align:right;">
14.13939
</td>
<td style="text-align:left;">
Confirmed
</td>
</tr>
</tbody>
</table>
</div>
<div id="conclusion-for-boruta-random-forest-test-raw-data" class="section level3">
<h3><span class="header-section-number">3.2.22</span> Conclusion for Boruta random forest test, RAW Data</h3>
<ul>
<li>All features are essential. None should be dropped.</li>
</ul>
</div>
<div id="conclusions-for-eda-raw-data" class="section level3">
<h3><span class="header-section-number">3.2.23</span> Conclusions For EDA, RAW data</h3>
<p>Three amino acids (C, F, I) from the single amino acid percent composition were deemed problematic due to their skewness were greater than 2.0. This suggests that a transformation should be carried out to rectify this issue.</p>
<table>
<thead>
<tr class="header">
<th align="left">Protein</th>
<th align="center">Skewness</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">C, Cysteine</td>
<td align="center">2.538162</td>
</tr>
<tr class="even">
<td align="left">F, Phenolalanine</td>
<td align="center">2.128118</td>
</tr>
<tr class="odd">
<td align="left">I, Isoleucine</td>
<td align="center">2.192145</td>
</tr>
</tbody>
</table>
<hr />
</div>
</div>
<div id="analysis-of-transformed-data" class="section level2">
<h2><span class="header-section-number">3.3</span> Analysis of TRANSFORMED data</h2>
<p><strong>This EDA section is a reevaluation square root transformed, <code>c_m_RAW_ACC.csv</code> data set, hence called <code>c_m_TRANSFORMED.csv.</code> </strong></p>
<p>The <span class="math inline">\(\sqrt x_i\)</span> <em>Transformed</em> data is derived from <code>c_m_RAW_ACC.csv</code> where the amino acids C, F, I were transformed using a square root function. This transformation was done to reduce the skewness of these samples and avoid modeling problems arising from high skewness, as seen below.</p>
<table>
<thead>
<tr class="header">
<th align="left">Amino Acid</th>
<th align="center">Initial skewness</th>
<th align="center">Skew After Square-Root Transformation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">C, Cysteine</td>
<td align="center">2.538162</td>
<td align="center">0.3478132</td>
</tr>
<tr class="even">
<td align="left">F, Phenolalanine</td>
<td align="center">2.128118</td>
<td align="center">-0.102739</td>
</tr>
<tr class="odd">
<td align="left">I, Isoleucine</td>
<td align="center">2.192145</td>
<td align="center">0.2934749</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb36-1" data-line-number="1"><span class="co"># Import Transformed data</span></a>
<a class="sourceLine" id="cb36-2" data-line-number="2">c_m_TRANSFORMED &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;./00-data/02-aac_dpc_values/c_m_TRANSFORMED.csv&quot;</span>)</a>
<a class="sourceLine" id="cb36-3" data-line-number="3">Class &lt;-<span class="st"> </span><span class="kw">as.factor</span>(c_m_TRANSFORMED<span class="op">$</span>Class)</a></code></pre></div>
<div id="check-transformed-dataframe-dimensions" class="section level3">
<h3><span class="header-section-number">3.3.1</span> Check Transformed dataframe dimensions</h3>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb37-1" data-line-number="1"><span class="kw">dim</span>(c_m_TRANSFORMED)</a></code></pre></div>
<pre><code>## [1] 2340   23</code></pre>
</div>
<div id="check-transformed-for-missing-values" class="section level3">
<h3><span class="header-section-number">3.3.2</span> Check Transformed for missing values</h3>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb39-1" data-line-number="1"><span class="kw">apply</span>(<span class="kw">is.na</span>(c_m_TRANSFORMED), <span class="dv">2</span>, which)</a></code></pre></div>
<pre><code>## integer(0)</code></pre>
<ul>
<li>No missing values found.</li>
</ul>
</div>
<div id="count-transformed-data-for-the-number-of-polypeptides-per-class" class="section level3">
<h3><span class="header-section-number">3.3.3</span> Count Transformed data for the number of polypeptides per class</h3>
<p>Number of polypeptides per Class:</p>
<ul>
<li>Class 0 = Control,</li>
<li>Class 1 = Myoglobin</li>
</ul>
<pre><code>## 
##    0    1 
## 1216 1124</code></pre>
</div>
<div id="visualization-descriptive-statistics-transformed-data" class="section level3">
<h3><span class="header-section-number">3.3.4</span> Visualization Descriptive Statistics, TRANSFORMED data</h3>
<p>Formulas for mean:
<span class="math display">\[\begin{equation} 
E[X] = \sum_{i=1}^n x_i p_i ~~; ~~~~~~ \bar x = \frac {1}{n} \sum_{i=1}^n x_i
\end{equation}\]</span></p>
</div>
<div id="scatter-plot-of-means-of-myoglobin-control-amino-acid-composition-sqrt-x_i-transformed-data" class="section level3">
<h3><span class="header-section-number">3.3.5</span> Scatter plot of means of <em>Myoglobin-Control</em> amino acid composition <span class="math inline">\(\sqrt x_i\)</span>, TRANSFORMED data</h3>
<ul>
<li>This plot shows the means for each feature (column-means) in the dataset. The means represent the ungrouped or total of all proteins (where n=2340) versus AA type.</li>
</ul>
<p><img src="_main_files/figure-html/237-1.png" width="672" /></p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb42-1" data-line-number="1"><span class="co"># A-4</span></a>
<a class="sourceLine" id="cb42-2" data-line-number="2"><span class="co">## Grouped barchart of $\sqrt x_i$ Transformed amino acid vs.</span></a>
<a class="sourceLine" id="cb42-3" data-line-number="3"><span class="co">## protein category data</span></a>
<a class="sourceLine" id="cb42-4" data-line-number="4"><span class="kw">barplot</span>(percent_aa,</a>
<a class="sourceLine" id="cb42-5" data-line-number="5">        <span class="dt">main =</span> <span class="st">&quot;Mean % A.A.Composition, TRANSFORMED data&quot;</span>,</a>
<a class="sourceLine" id="cb42-6" data-line-number="6">        <span class="dt">ylab =</span> <span class="st">&quot;% AA Composition&quot;</span>,</a>
<a class="sourceLine" id="cb42-7" data-line-number="7">        <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">30</span>),</a>
<a class="sourceLine" id="cb42-8" data-line-number="8">        <span class="dt">col =</span> <span class="kw">colorRampPalette</span>(<span class="kw">brewer.pal</span>(<span class="dv">4</span>, <span class="st">&quot;Blues&quot;</span>))(<span class="dv">3</span>),</a>
<a class="sourceLine" id="cb42-9" data-line-number="9">        <span class="dt">legend =</span> T,</a>
<a class="sourceLine" id="cb42-10" data-line-number="10">        <span class="dt">beside =</span> T)</a></code></pre></div>
</div>
<div id="grouped-bar-chart-of-means-for-percent-amino-acid-composition-of-transformed-data-control-myoglobin-categories" class="section level3">
<h3><span class="header-section-number">3.3.6</span> Grouped bar chart of means for percent amino acid composition of Transformed Data; control &amp; myoglobin categories</h3>
<p><img src="_main_files/figure-html/240-1.png" width="672" /></p>
</div>
<div id="boxplots-of-grand-means-of-the-overall-amino-acid-composition-of-square-root-transformed-data" class="section level3">
<h3><span class="header-section-number">3.3.7</span> Boxplots of grand-means of the overall amino acid composition of square-root transformed data</h3>
<p><img src="_main_files/figure-html/241-1.png" width="672" /></p>
</div>
<div id="boxplots-of-amino-acid-compositions-for-control-only-of-square-root-transformed-data" class="section level3">
<h3><span class="header-section-number">3.3.8</span> Boxplots of amino acid compositions for control (only) of square-root transformed data</h3>
<p><img src="_main_files/figure-html/242-1.png" width="672" /></p>
</div>
<div id="boxplots-of-amino-acid-compositions-for-myoglobin-of-square-root-transformed-dataonly-transformed-data" class="section level3">
<h3><span class="header-section-number">3.3.9</span> Boxplots of amino acid compositions for myoglobin of square-root transformed Data(only), TRANSFORMED data</h3>
<p><img src="_main_files/figure-html/243-1.png" width="672" /></p>
</div>
<div id="boxplots-of-length-of-polypeptides-of-transformed-data-myoglobin-control-combined" class="section level3">
<h3><span class="header-section-number">3.3.10</span> Boxplots Of Length Of Polypeptides Of Transformed Data; Myoglobin, Control &amp; Combined</h3>
<p><img src="_main_files/figure-html/244-1.png" width="672" /></p>
</div>
<div id="coefficient-of-variance-cv-transformed-data" class="section level3">
<h3><span class="header-section-number">3.3.11</span> Coefficient of Variance (CV), TRANSFORMED data</h3>
<p>Standard deviations are sensitive to scale. Therefore I compare the normalized standard deviations. This normalized standard deviation is more commonly called the coefficient of variation (CV).</p>
<p><span class="math display">\[\begin{equation} 
CV = \frac {\sigma (x)} {E [|x|]} ~~~ where ~~~ \sigma(x) \equiv \sqrt{ E[x - \mu]^2 }
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation} 
CV ~~=~~ \frac{1}{\bar x} \cdot \sqrt{ \frac{1}{n-1} \sum^n_{i=1} (x_i - \bar x)^2}
\end{equation}\]</span></p>
</div>
<div id="plot-of-coefficient-of-variance-cv" class="section level3">
<h3><span class="header-section-number">3.3.12</span> Plot of Coefficient Of Variance (CV)</h3>
<p><img src="_main_files/figure-html/245-1.png" width="672" /></p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb43-1" data-line-number="1">AA_var_norm</a></code></pre></div>
<pre><code>##         A         C         D         E         F         G         H         I         K 
## 0.6095112 0.8729758 0.5478540 0.4156102 0.2815745 0.5201625 0.7966296 0.2999687 0.4689544 
##         L         M         N         P         Q         R         S         T         V 
## 0.3215591 0.6529752 0.7352478 0.7383244 0.5752622 0.7680977 0.4948690 0.5830352 0.4420595 
##         W         Y 
## 0.9461276 0.8461615</code></pre>
</div>
<div id="skewness-of-distributions-transformed-data" class="section level3">
<h3><span class="header-section-number">3.3.13</span> Skewness of distributions, TRANSFORMED data</h3>
<p><span class="math display">\[\begin{equation} 
Skewness ~= E\left[ \left( \frac{X - \mu}{\sigma(x)} \right)^3 \right] ~~~~ where ~~~~ \sigma(x) \equiv \sqrt{ E[x - \mu]^2 }
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation} 
Skewness ~= \frac { \frac{1}{n} \sum^n_{i=1} (x_i - \bar x)^3 } { \left( \sqrt{ \frac{1}{n-1} \sum^n_{i=1} (x_i - \bar x)^2 } \right) ^ {3}}
\end{equation}\]</span></p>
<ul>
<li>Skewness values for each A.A. by Class of square-root transformed data</li>
</ul>
<p><img src="_main_files/figure-html/247-1.png" width="672" /></p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb45-1" data-line-number="1">AA_skewness</a></code></pre></div>
<pre><code>##            A            C            D            E            F            G            H 
##  0.670502595  0.347813248 -0.058540442  1.782876260 -0.102739748  0.091338300  1.135783661 
##            I            K            L            M            N            P            Q 
##  0.293474879  0.223433207 -0.172566877  0.744002991  0.633532783  1.493903282  0.306716333 
##            R            S            T            V            W            Y 
##  1.241930812  1.448521897 -0.006075043  1.338971930  1.831047440  1.694362388</code></pre>
</div>
<div id="determine-coefficients-of-correlation-transformed-data" class="section level3">
<h3><span class="header-section-number">3.3.14</span> Determine coefficients of correlation, TRANSFORMED data</h3>
<p>An easily interpretable test is a correlation 2D-plot for investigating multicollinearity or feature reduction. Fewer attributes “means decreased computational time and complexity. Secondly, if two predictors are highly correlated, this implies that they measure the same underlying information. Removing one should not compromise the performance of the model and might lead to a more parsimonious and interpretable model. Third, some models can be crippled by predictors with degenerate distributions.” <a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a></p>
<p>Pearson’s correlation coefficient:
<span class="math display">\[\begin{equation} 
\rho_{x,y} = \frac {E \left[(X - \mu_x)(X - \mu_y) \right]} {\sigma_x \sigma_y}
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation} 
r_{xy} = \frac {\sum^n_{i=1} (x_i - \bar x)(y_1 - \bar y)} { {\sqrt {\sum^n_{i=1} (x_i - \bar x)^2 }} {\sqrt {\sum^n_{i=1} (y_i - \bar y)^2 }} }
\end{equation}\]</span></p>
<p><img src="_main_files/figure-html/250-1.png" width="672" /></p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb47-1" data-line-number="1">c_m_corr_mat[<span class="st">&quot;T&quot;</span>, <span class="st">&quot;N&quot;</span>]</a></code></pre></div>
<pre><code>## [1] 0.7098085</code></pre>
<p><strong>No values in the correlation matrix meet the 0.75 cut off criteria for problems.</strong></p>
</div>
<div id="boruta---dimensionality-reduction-transformed-data" class="section level3">
<h3><span class="header-section-number">3.3.15</span> Boruta - Dimensionality Reduction, TRANSFORMED data</h3>
<p><strong>Perform Boruta search</strong></p>
<p>NOTE: <em>mcAdj = TRUE</em>: If True, multiple comparisons will be adjusted using the Bonferroni method to calculate p-values. Therefore, <span class="math inline">\(p_i \leq \frac {\alpha} {m}\)</span> where <span class="math inline">\(\alpha\)</span> is the desired p-value and <span class="math inline">\(m\)</span> is the total number of null hypotheses.</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb49-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">1000</span>)</a>
<a class="sourceLine" id="cb49-2" data-line-number="2"><span class="co">#registerDoMC(cores = 3) # Start multi-processor mode</span></a>
<a class="sourceLine" id="cb49-3" data-line-number="3">start_time &lt;-<span class="st"> </span><span class="kw">Sys.time</span>() <span class="co"># Start timer</span></a>
<a class="sourceLine" id="cb49-4" data-line-number="4"></a>
<a class="sourceLine" id="cb49-5" data-line-number="5">boruta_output &lt;-<span class="st"> </span><span class="kw">Boruta</span>(Class <span class="op">~</span><span class="st"> </span>.,</a>
<a class="sourceLine" id="cb49-6" data-line-number="6">                        <span class="dt">data =</span> c_m_class_<span class="dv">20</span>[, <span class="dv">-1</span>],</a>
<a class="sourceLine" id="cb49-7" data-line-number="7">                        <span class="dt">mcAdj =</span> <span class="ot">TRUE</span>, <span class="co"># See Note above.</span></a>
<a class="sourceLine" id="cb49-8" data-line-number="8">                        <span class="dt">doTrace =</span> <span class="dv">1</span>) <span class="co"># doTrace = 1, represents non-verbose mode.</span></a>
<a class="sourceLine" id="cb49-9" data-line-number="9"></a>
<a class="sourceLine" id="cb49-10" data-line-number="10"><span class="co">#registerDoSEQ() # Stop multi-processor mode</span></a>
<a class="sourceLine" id="cb49-11" data-line-number="11">end_time &lt;-<span class="st"> </span><span class="kw">Sys.time</span>() <span class="co"># End timer</span></a>
<a class="sourceLine" id="cb49-12" data-line-number="12">end_time <span class="op">-</span><span class="st"> </span>start_time <span class="co"># Display elapsed time</span></a></code></pre></div>
<pre><code>## Time difference of 28.80269 secs</code></pre>
</div>
<div id="plot-variable-importance-transformed-data" class="section level3">
<h3><span class="header-section-number">3.3.16</span> Plot Variable Importance, TRANSFORMED data</h3>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb51-1" data-line-number="1"><span class="kw">plot</span>(boruta_output,</a>
<a class="sourceLine" id="cb51-2" data-line-number="2">     <span class="dt">cex.axis =</span> <span class="dv">1</span>,</a>
<a class="sourceLine" id="cb51-3" data-line-number="3">     <span class="dt">las =</span> <span class="dv">2</span>,</a>
<a class="sourceLine" id="cb51-4" data-line-number="4">     <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">5</span>, <span class="dv">50</span>),</a>
<a class="sourceLine" id="cb51-5" data-line-number="5">     <span class="dt">main =</span> <span class="st">&quot;Variable Importance, TRANSFORMED data(Bigger=Better)&quot;</span>)</a></code></pre></div>
<p><img src="_main_files/figure-html/254-1.png" width="672" /></p>
</div>
<div id="variable-importance-scores-transformed-data" class="section level3">
<h3><span class="header-section-number">3.3.17</span> Variable Importance Scores, TRANSFORMED data</h3>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb52-1" data-line-number="1">roughFixMod &lt;-<span class="st"> </span><span class="kw">TentativeRoughFix</span>(boruta_output)</a>
<a class="sourceLine" id="cb52-2" data-line-number="2">imps &lt;-<span class="st"> </span><span class="kw">attStats</span>(roughFixMod)</a>
<a class="sourceLine" id="cb52-3" data-line-number="3">imps2 &lt;-<span class="st"> </span>imps[imps<span class="op">$</span>decision <span class="op">!=</span><span class="st"> &quot;Rejected&quot;</span>, <span class="kw">c</span>(<span class="st">&quot;meanImp&quot;</span>, <span class="st">&quot;decision&quot;</span>)]</a>
<a class="sourceLine" id="cb52-4" data-line-number="4">meanImps &lt;-<span class="st"> </span>imps2[<span class="kw">order</span>(<span class="op">-</span>imps2<span class="op">$</span>meanImp), ] <span class="co"># descending sort</span></a>
<a class="sourceLine" id="cb52-5" data-line-number="5"></a>
<a class="sourceLine" id="cb52-6" data-line-number="6"><span class="kw">kable</span>(meanImps) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">kable_styling</span>(<span class="dt">bootstrap_options =</span> <span class="kw">c</span>(<span class="st">&quot;striped&quot;</span>, <span class="st">&quot;hover&quot;</span>))</a></code></pre></div>
<table class="table table-striped table-hover" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
meanImp
</th>
<th style="text-align:left;">
decision
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
R
</td>
<td style="text-align:right;">
43.17613
</td>
<td style="text-align:left;">
Confirmed
</td>
</tr>
<tr>
<td style="text-align:left;">
H
</td>
<td style="text-align:right;">
34.30370
</td>
<td style="text-align:left;">
Confirmed
</td>
</tr>
<tr>
<td style="text-align:left;">
P
</td>
<td style="text-align:right;">
28.70674
</td>
<td style="text-align:left;">
Confirmed
</td>
</tr>
<tr>
<td style="text-align:left;">
C
</td>
<td style="text-align:right;">
27.72357
</td>
<td style="text-align:left;">
Confirmed
</td>
</tr>
<tr>
<td style="text-align:left;">
K
</td>
<td style="text-align:right;">
27.60838
</td>
<td style="text-align:left;">
Confirmed
</td>
</tr>
<tr>
<td style="text-align:left;">
E
</td>
<td style="text-align:right;">
26.18872
</td>
<td style="text-align:left;">
Confirmed
</td>
</tr>
<tr>
<td style="text-align:left;">
Y
</td>
<td style="text-align:right;">
22.84975
</td>
<td style="text-align:left;">
Confirmed
</td>
</tr>
<tr>
<td style="text-align:left;">
T
</td>
<td style="text-align:right;">
21.66359
</td>
<td style="text-align:left;">
Confirmed
</td>
</tr>
<tr>
<td style="text-align:left;">
S
</td>
<td style="text-align:right;">
21.44119
</td>
<td style="text-align:left;">
Confirmed
</td>
</tr>
<tr>
<td style="text-align:left;">
A
</td>
<td style="text-align:right;">
20.54316
</td>
<td style="text-align:left;">
Confirmed
</td>
</tr>
<tr>
<td style="text-align:left;">
N
</td>
<td style="text-align:right;">
20.10100
</td>
<td style="text-align:left;">
Confirmed
</td>
</tr>
<tr>
<td style="text-align:left;">
V
</td>
<td style="text-align:right;">
18.77068
</td>
<td style="text-align:left;">
Confirmed
</td>
</tr>
<tr>
<td style="text-align:left;">
I
</td>
<td style="text-align:right;">
18.69155
</td>
<td style="text-align:left;">
Confirmed
</td>
</tr>
<tr>
<td style="text-align:left;">
F
</td>
<td style="text-align:right;">
18.18632
</td>
<td style="text-align:left;">
Confirmed
</td>
</tr>
<tr>
<td style="text-align:left;">
D
</td>
<td style="text-align:right;">
17.64435
</td>
<td style="text-align:left;">
Confirmed
</td>
</tr>
<tr>
<td style="text-align:left;">
G
</td>
<td style="text-align:right;">
16.15207
</td>
<td style="text-align:left;">
Confirmed
</td>
</tr>
<tr>
<td style="text-align:left;">
W
</td>
<td style="text-align:right;">
15.77085
</td>
<td style="text-align:left;">
Confirmed
</td>
</tr>
<tr>
<td style="text-align:left;">
L
</td>
<td style="text-align:right;">
15.27614
</td>
<td style="text-align:left;">
Confirmed
</td>
</tr>
<tr>
<td style="text-align:left;">
M
</td>
<td style="text-align:right;">
14.83421
</td>
<td style="text-align:left;">
Confirmed
</td>
</tr>
<tr>
<td style="text-align:left;">
Q
</td>
<td style="text-align:right;">
14.12976
</td>
<td style="text-align:left;">
Confirmed
</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb53-1" data-line-number="1"><span class="co"># knitr::kable(meanImps,</span></a>
<a class="sourceLine" id="cb53-2" data-line-number="2"><span class="co"># full_width = F,</span></a>
<a class="sourceLine" id="cb53-3" data-line-number="3"><span class="co"># position = &quot;left&quot;,</span></a>
<a class="sourceLine" id="cb53-4" data-line-number="4"><span class="co"># caption = &quot;Mean Importance Scores &amp; Decision, TRANSFORMED data&quot;)</span></a></code></pre></div>
<p>The <em>Boruta Random Rorest test</em> shows that all features are essential therefore none should be dropped from TRANSFORMED data.</p>
</div>
</div>
<div id="eda-conclusion" class="section level2">
<h2><span class="header-section-number">3.4</span> EDA Conclusion</h2>
<div id="feature-selection-extraction" class="section level3">
<h3><span class="header-section-number">3.4.1</span> Feature Selection &amp; Extraction</h3>
<p>It was determined early on that three amino acids (C, F, I) from the data amino acid percent compositions (c_m_RAW_AAC.csv) had Skewness greater than two. It was found that tranforming the features using the square root function lowered the skewness to {-0.102739 <span class="math inline">\(\leq\)</span> skew after transformation <span class="math inline">\(\leq\)</span> 0.3478132}.</p>
<p>Table 7.1, Skewness Before And After Square-Root Transform</p>
<table>
<thead>
<tr class="header">
<th align="left">Amino Acid</th>
<th align="center">Initial Skewness</th>
<th align="center">Skew After Square-Root Transform</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">C, Cysteine</td>
<td align="center">2.538162</td>
<td align="center">0.347813248</td>
</tr>
<tr class="even">
<td align="left">F, Phenolalanine</td>
<td align="center">2.128118</td>
<td align="center">-0.102739748</td>
</tr>
<tr class="odd">
<td align="left">I, Isoleucine</td>
<td align="center">2.192145</td>
<td align="center">0.293474879</td>
</tr>
</tbody>
</table>
<p>The transformations of the three amino acids (C, F, I) did not appriciably change the Correlation coefficient, R. Therefore no R values were above 0.75 before or after testing. The highest coeffiecient of correlation being Threonine and Argnine with an R of 0.7098. This indicates that no features are collinear. Therefore the transformed data is used throughout this experiment.</p>
<hr />
</div>
<div id="information-block" class="section level3">
<h3><span class="header-section-number">3.4.2</span> Information Block**</h3>
<p>How to: Dimension Reduction using High Correlation</p>
<p>How to reduce features given high correlation (|R| &gt;= 0.75) {-}</p>
<ol style="list-style-type: decimal">
<li><p>Calculate the correlation matrix of the predictors.</p></li>
<li><p>If the correlation plot produced of any two variables is greater than or equal to (|R| &gt;= 0.75), then we could consider feature elimination. This interesting heuristic approach would be used for determining which feature to eliminate.<a href="#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a></p></li>
<li><p>Determine if the two predictors associated with the most significant absolute pairwise correlation (R &gt; |0.75|), call them predictors A and B.</p></li>
<li><p>Determine the average correlation between A and the other variables. Do the same for predictor B.</p></li>
<li><p>If A has a more significant average correlation, remove it; otherwise, remove predictor B.</p></li>
<li><p>Repeat Steps 2–4 until no absolute correlations are above the threshold.</p></li>
</ol>
<hr />
<p>An alternative test for variable importance carried out is called Boruta. Boruta builds Random Forests then “finds relevant features by comparing original attributes’ importance with importance achievable at random.” <a href="#fn12" class="footnote-ref" id="fnref12"><sup>12</sup></a></p>
<p>Boruta is used for dimensionality reduction of the <strong>c_m_Transformed data</strong>. Bortua showed that all dependent features are essential for the generation of a Random Forest Decision Tree. It would wise to keep all features for that model test and throughout the generation of other models. All features have decisive mean importance, which is generated by a Gini calculation.</p>

</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p><a href="https://en.wikipedia.org/wiki/Exploratory_data_analysis" class="uri">https://en.wikipedia.org/wiki/Exploratory_data_analysis</a><a href="exploratory-data-analysis.html#fnref1" class="footnote-back">↩</a></p></li>
<li id="fn2"><p><a href="https://www.itl.nist.gov/div898/handbook/" class="uri">https://www.itl.nist.gov/div898/handbook/</a><a href="exploratory-data-analysis.html#fnref2" class="footnote-back">↩</a></p></li>
<li id="fn3"><p>Roger Peng, Exploratory Data Analysis with R, <a href="https://leanpub.com/exdata" class="uri">https://leanpub.com/exdata</a>, 2016<a href="exploratory-data-analysis.html#fnref3" class="footnote-back">↩</a></p></li>
<li id="fn4"><p>Ronald Pearson, Exploratory Data Analysis Using R, CRC Press, <a href="ISBN:9781138480605" class="uri">ISBN:9781138480605</a>, 2018<a href="exploratory-data-analysis.html#fnref4" class="footnote-back">↩</a></p></li>
<li id="fn5"><p>Miron Kursa, Witold Rudnicki, Feature Selection with the Boruta Package, <a href="DOI:10.18637/jss.v036.i11" class="uri">DOI:10.18637/jss.v036.i11</a>, 2010<a href="exploratory-data-analysis.html#fnref5" class="footnote-back">↩</a></p></li>
<li id="fn6"><p>Ronald Pearson, Exploratory Data Analysis Using R, CRC Press, <a href="ISBN:9781138480605" class="uri">ISBN:9781138480605</a>, 2018<a href="exploratory-data-analysis.html#fnref6" class="footnote-back">↩</a></p></li>
<li id="fn7"><p>Max Kuhn and Kjell Johnson, Applied Predictive Modeling, Springer Publishing, 2018, P.43<a href="exploratory-data-analysis.html#fnref7" class="footnote-back">↩</a></p></li>
<li id="fn8"><p>Max Kuhn and Kjell Johnson, Applied Predictive Modeling, Springer Publishing, 2018, P.47 (<a href="http://appliedpredictivemodeling.com/" class="uri">http://appliedpredictivemodeling.com/</a>)<a href="exploratory-data-analysis.html#fnref8" class="footnote-back">↩</a></p></li>
<li id="fn9"><p><a href="https://notabug.org/mbq/Boruta/" class="uri">https://notabug.org/mbq/Boruta/</a><a href="exploratory-data-analysis.html#fnref9" class="footnote-back">↩</a></p></li>
<li id="fn10"><p>Max Kuhn and Kjell Johnson, Applied Predictive Modeling, Springer Publishing, 2018<a href="exploratory-data-analysis.html#fnref10" class="footnote-back">↩</a></p></li>
<li id="fn11"><p>Max Kuhn and Kjell Johnson, Applied Predictive Modeling, Springer Publishing, 2018, (<a href="http://appliedpredictivemodeling.com/" class="uri">http://appliedpredictivemodeling.com/</a>)<a href="exploratory-data-analysis.html#fnref11" class="footnote-back">↩</a></p></li>
<li id="fn12"><p><a href="https://notabug.org/mbq/Boruta/" class="uri">https://notabug.org/mbq/Boruta/</a><a href="exploratory-data-analysis.html#fnref12" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introduction-what-is-machine-learning.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="principle-component-analysis-of-a-binary-classification-system.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
